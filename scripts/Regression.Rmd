---
title: "Regression"
author: "Claire Hsieh"
date: "2024-04-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Initialization

```{r}
library(glmnet)
library(reticulate)
library(tidyverse)
library(glue)
library(stringr)

# Seeing your environments
conda_list()

conda_list()[[1]][3] %>% 
use_condaenv(required = TRUE)

# Using python b/c there's no way I'm re-writing anything in R
source_python("print_h5py_file.py")
np <- import("numpy", convert = FALSE)

brain_size = read_csv("../data/gyz043_suppl_Supplement_Data.csv")
brain_size$Binomial <- tolower(brain_size$Binomial)

```

# Regression

```{r}
some_regression <- function(species_internal, brain_size, feature_select = TRUE, p_vals = FALSE){
  # reformat data 
  # only keep cols of internal matrix that we have brain_size data for
  # subset brain_size to only keep rows for species in internal matrix
  x = species_internal[[1]]
  x <- as.data.frame(x)
  x <- x[, rowSums(x != 0) > 0]
  new_df <- data.frame(colnames(x))
  colnames(new_df) = c("Binomial")
  merged = left_join(new_df, brain_size, by = c("Binomial"))[c("Binomial", "Brain.resid")]
  x = t(x[na.omit(merged)$Binomial])
  y = na.omit(merged$Brain.resid)
  
  if (feature_select == TRUE){
    glmnet1<-glmnet::cv.glmnet(x=x,y=y,type.measure='mse')
    co<-coef(glmnet1,s = "lambda.1se") # value of lambda that gives the simplest model within one standard error of the minimum cross-validated error.
    inds<-which(co!=0)
    variables<-row.names(co)[inds]
    variables<-variables[!(variables %in% '(Intercept)')];
    return(variables)
  }
  
  else if (p_vals == TRUE){
    summ = summary(glm(y ~ x))
    return(summ)
  }
  else{
    cvfit <- cv.glmnet(x, y)
    return(cvfit)
  }


} 
```


```{r}
# Feature Selection

# loop through trees with >50 species in brain size dataset
# do feature selection using cv.glmnet
# output: files with format:  {tree_number}, {significant node}

num = 50
num_files = 0
for(num in c(50:64)){
num_files = length(list.files(glue("../trees/brain/{num}/"))) + num_files
}


for(num in c(50:64)){
  file.create(glue("sig_vals/significant_vals_{num}.txt"))
  files <- list.files(path=glue("../trees/brain/{num}/"), pattern="species_internal*", full.names=TRUE, recursive=FALSE)
  for (fl in files){
    match <- str_extract(fl, "_\\d+")
    i = substr(str_extract(match, "_\\d+"), 2, nchar(match))
    tryCatch({
      species = print_h5py_file(glue("../trees/brain/{num}/species_{i}.h5"), "species")
      species_internal = print_h5py_file(glue("../trees/brain/{num}/species_internal_{i}.h5"), "species_internal", cols=np$array(species[[5]]))
      vars = some_regression(species_internal, brain_size)
      if ((length(vars) > 0)) {
        write(glue("{i}, {vars}"), glue("sig_vals/significant_vals_{num}.txt"), append=TRUE)
      } 
    })
  }
}

```

# Selecting Trees

```{r}
rank_trees <- function(species_internal, brain_size){
  x = species_internal[[1]]
  new_df <- data.frame(colnames(x))
  colnames(new_df) = c("Binomial")
  merged = left_join(new_df, brain_size, by = c("Binomial"))[c("Binomial", "Brain.resid")]
  x = t(x[na.omit(merged)$Binomial]) 
  x <- x[, rowSums(x != 0) > 0] %>% scale()
  x[is.nan(x)] <- 0
  y = scale(na.omit(merged$Brain.resid))
  glmnet1<-glmnet::cv.glmnet(x=x,y=y,type.measure='mse', standardize=FALSE)
  # if standardize=TRUE, glmnet standardizes x values, but coefficients are returned on original scale
  rsq = 1 - glmnet1$cvm/var(y)
  tmp = c(glmnet1$cvm[1], min(glmnet1$cvm), mean(glmnet1$cvsd), max(rsq))
  # use max R-squared??, why are delta and R2 comparable anyway??
  return(tmp)
  # should i have something that takes into account standard error??
  # return(c(glmnet1$cvm[1], min(glmnet1$cvm), mean(glmnet1$cvsd)))
} 

```


```{r}
for(num in c(50:64)){
  file.create(glue("../claires-secret-folder/sig_vals/std/{num}.txt"))
  files <- list.files(
              path=glue("../trees/brain/{num}/"), 
              pattern="species_internal*", 
              full.names=TRUE, 
              recursive=FALSE)
  
  for (fl in files){
    match <- str_extract(fl, "_\\d+")
    i = substr(str_extract(match, "_\\d+"), 2, nchar(match))
    
    tryCatch({
      # print(glue("{num}, {i}"))
      species = print_h5py_file(
                glue("../trees/brain/{num}/species_{i}.h5"), 
                "species")
      species_internal = print_h5py_file(
                glue("../trees/brain/{num}/species_internal_{i}.h5"), 
                "species_internal", 
                cols=np$array(species[[5]]))
      
      tmp = rank_trees(species_internal, brain_size)
      delta = round(tmp[1] - tmp[2], digits = 10)
      # if((tmp[1] - tmp[2]) > (tmp[2] + tmp[3])){
      write(glue("{i}, {delta}, {tmp[3]}, {tmp[4]}"), 
            file = glue("../claires-secret-folder/sig_vals/std/{num}.txt"), 
            append=TRUE)
      # num_species_in_tree_tree_num, difference in mse, mean std dev, R2
      # }
    })
  }
}
```


# Obtaining model from selected parameters

```{r}
# coeficients of the final model
coef_cv=coef(glmnet1, s = "lambda.min")
# prediction of the final model
predict(glmnet1, newx = x[1:5,], s = "lambda.min")

# extract optimal lambda
lmabda_opt=glmnet1$lambda.min 

# manually plugging lambda into glmnet
fit_2 = glmnet(x, y,lambda = lmabda_opt) 

# compare cefficients - equal
cbind(coef_cv,coef(fit_2))

# compare predictions - equal
cbind(predict(cvfit, newx = x[1:5,], s = "lambda.min"),predict(fit_2, newx = x[1:5,]))
```








